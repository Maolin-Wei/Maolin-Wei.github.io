<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Maolin Wei</title>

  <meta name="author" content="Maolin Wei">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="6qogr8z7RZgR_SCX2GSXZNaoOxokGl59tYYreLe6uEg" />
  <meta property="og:image" content="images/photo1.png" />
  <meta name="og:title" content="Maolin Wei" />
  <meta name="title" content="Maolin Wei" />
  <link rel=" stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>


<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Maolin Wei</name>
                  <p>I am a first-year PhD student at Boston University, advised by Prof. <a
                      href="https://eshed1.github.io/">Eshed Ohn-Bar</a>. I received my Master's degree (2023-2025), also from Boston University.

                  <p style="text-align:center">
                    <a href="mailto:mlwei@bu.edu">Email</a> &nbsp/&nbsp
                    <a href="https://github.com/Maolin-Wei/">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/maolin-wei/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/photo1.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/photo1.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>My research interests lie in large language models, computer vision, and machine learning with their applications in autonomous and assistive systems.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>





              <!-- <tr onmouseout="eccv_2024_stop()" onmouseover="eccv_2024_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='eccv_2024_video'><video width=100% muted autoplay loop>
                        <source src="images/Nemo_vid.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <div id='eccv_2024_still'><img src='images/Nemo_pic.png' width=100%></div>
                  </div>
                  <script type="text/javascript">
                    function eccv_2024_start() {
                      document.getElementById('eccv_2024_video').style.display = 'inline';
                      document.getElementById('eccv_2024_still').style.display = 'none';
                    }

                    function eccv_2024_stop() {
                      document.getElementById('eccv_2024_video').style.display = 'none';
                      document.getElementById('eccv_2024_still').style.display = 'inline';
                    }
                    eccv_2024_stop()
                  </script>
                </td>



                <td
                  style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:75%;vertical-align:middle">
                  <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02571.pdf">
                    <papertitle>Neural Volumetric World Models for Autonomous Driving
                      </papertitle>
                  </a>
                  <br>
                  <strong>Jimuyang Zhang*</strong>, <a href="https://tzmhuang.github.io/">Zanming Huang*,
                   <a href="https://scholar.google.com/citations?user=p9zVBV4AAAAJ&hl=en&oi=ao">Eshed Ohn-Bar</a>
                  <br>
                  <em>European Conference on Computer Vision (ECCV)</em>, 2024
                  <br>
                  <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02571.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://eccv.ecva.net/virtual/2024/poster/250">webpage</a> &nbsp/&nbsp
                  <a href="https://youtu.be/HYFvPfyaZfM">video</a>
                  <p></p>
                  <p>We introduce NeMo, a neural volumetric world modeling approach that can be trained in a self-supervised manner for image reconstruction and 
                    occupancy prediction tasks, benefiting scalable training and deployment paradigms such as imitation learning. We demonstrate how the higher-fidelity 
                    modeling of 3D volumetric representations benefits vision-based motion planning. We propose a motion flow module to model complex dynamic scenes, and
                    introduce a temporal attention module to effectively integrate predicted future volumetric features for the planning task.
                  </p>
                </td>
              </tr> -->
              <!-- END PAPER NeMo -->

              <!-- START PAPER DriveQA -->
               <!-- <tr onmouseout="iccv_2025_stop()" onmouseover="iccv_2025_start()"> -->
                <td style="padding:20px;width:50%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='iccv_2025_video'><video width=100% muted autoplay loop>
                        <source src="images/FeD_short.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div> -->
                    <div id='iccv_2025_driveqa'><img src='images/iccv2025_driveQA.png' width=100%></div>
                  </div>
                  <!-- <script type="text/javascript">
                    function iccv_2025_start() {
                      document.getElementById('iccv_2025_video').style.display = 'inline';
                      document.getElementById('iccv_2025_still').style.display = 'none';
                    }

                    function iccv_2025_stop() {
                      document.getElementById('iccv_2025_video').style.display = 'none';
                      document.getElementById('iccv_2025_still').style.display = 'inline';
                    }
                    iccv_2025_stop()
                  </script> -->
                </td>

                <td
                  style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:75%;vertical-align:middle">
                  <a href="https://driveqaiccv.github.io/">
                    <papertitle>Passing the Driving Knowledge Test
                      </papertitle>
                  </a>
                  <br>
                  <a href="https://maolin-wei.github.io/"></a><strong>Maolin Wei*</strong>, <a href="https://wanzhouliu.github.io/">Wanzhou Liu*,
                   <a href="https://eshed1.github.io/">Eshed Ohn-Bar</a>
                  <br>
                  <em>International Conference on Computer Vision (ICCV)</em>, 2025
                  <br>
                  <!-- <strong><FONT COLOR="#ff0000">Highlight presentation (~top 2.8% of submitted papers)</FONT></strong> -->
                  <!-- <br> -->
                  <!-- <a href="https://jimuyangz.github.io/papers/FeD_v1.pdf">paper</a> &nbsp/&nbsp -->
                    <a href="https://driveqaiccv.github.io/">[Project Page]</a>
                  <!-- <a href="https://www.youtube.com/watch?v=0f6NQ7sn6hA">video</a> -->
                  <p></p>
                  <p>We present <strong>DriveQA</strong>, an extensive text and vision-based benchmark that exhaustively covers traffic regulations and scenarios. 
                    Through our experiments, we show that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on basic traffic rules 
                    but exhibit significant weaknesses in numerical reasoning and complex right-of-way scenarios, traffic sign variations, and spatial layouts, 
                    (2) fine-tuning on DriveQA improves accuracy across multiple categories, particularly in regulatory sign recognition and intersection decision-making, 
                    (3) controlled variations in DriveQA-V provide insights into model sensitivity to environmental factors such as lighting, perspective, distance, and weather conditions, 
                    and (4) pretraining on DriveQA enhances downstream driving task performance, leading to improved results on real-world datasets such as nuScenes and BDD, 
                    while also demonstrating that models can internalize text and synthetic traffic knowledge to generalize effectively across downstream QA tasks. 
                  </p>
                </td>
              <!-- </tr> -->

              <!-- END PAPER DriveQA -->


            </tbody>
          </table>


          <!-- Teaching -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Teaching</heading>

                  <p>
                    <a href="https://www.bu.edu/academics/eng/courses/eng-ec-518/">ENG EC 518 - Robot Learning and Vision for Navigation - Fall 2024</a>
                    <br>
                    Teaching Assistant
                  </p>

                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


            </tbody>
          </table>



          <!-- Service -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Service</heading>

                  <p>
                    <a href="https://accessibility-cv.github.io/">CVPR2025 AVA Accessibility Vision and Autonomy Challenge</a>
                    <br>
                    Challenge Organizer
                  </p>

                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


            </tbody>
          </table>



          <tables
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    This website was forked from <a href="https://github.com/jonbarron/jonbarron_website">source
                      code</a>

                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>




